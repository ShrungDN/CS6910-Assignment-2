Search space:
    # Hyperparameters that are not tuned/ tuned only on best model
        batch size: 64
        epochs: 10
        optimizer: Adam
        pooling layer: MaxPool2d
        dense layer size: 1000
        loss function: CrossEntropyLoss

    # Hyperparameters that are tuned (selectively):
        learning rate: [1e-3, 1e-4, 1e-5]
        data augmentation: [T, F]
        dropout: [0, 0.3]
        activation: [ReLU, GELU, SiLU, Mish]
        batch norm: [T, F]
        number of kernels: [[64, 64, 64, 64, 64],
                          [8, 16, 32, 64, 128],
                          [128, 64, 32, 16, 8]]
        shape of kernels: [[5, 5, 5, 5, 5],
                           [9, 9, 3, 3, 3],
                           [3, 3, 3, 9, 9]]

The sweeps are done selectively as follows:

sweeps 1-8: changing dropout, BN and lr: lr=sweep, da=False, dr=sweep, act=ReLU, bn=sweep, nk=64,64,64,64,64 sk=5,5,5,5,5
done 1. lr:1e-3, dropout: 0, BN: False
done 2. lr:1e-3, dropout: 0.3, BN: False
done 3. lr:1e-3, dropout: 0, BN: True
done 4. lr:1e-3, dropout: 0.3, BN: True
done 5. lr:1e-4, dropout: 0, BN: False
done 6. lr:1e-4, dropout: 0.3, BN: False
done 7. lr:1e-4, dropout: 0, BN: True
done 8. lr:1e-4, dropout: 0.3, BN: True
done 9. lr:1e-5, dropout: 0, BN: False
done 10. lr:1e-5, dropout: 0.3, BN: False
done 11. lr:1e-5, dropout: 0, BN: True
done 12. lr:1e-5, dropout: 0.3, BN: True

(choose best config from above)
sweeps 13-13: changing data augmentation: lr=1e-4, da=sweep, dr=0.3, act=ReLU, bn=True, nk=64,64,64,64,64 sk=5,5,5,5,5
done ~13. da: False  
done 13. da: True 

(choose best config from above)
sweeps 14-16 :changing activation: lr=1e-4,, da=False, dr=0.3, act=sweep, bn=True, nk=64,64,64,64,64 sk=5,5,5,5,5
done ~14. act: ReLU
done 14. act:GELU
done 15. act:SiLU
done 16. act:Mish

(choose best config from above)
sweeps 17-24 :kernel size and number: lr=1e-4,, da=False, dr=0.3, act=GELU, bn=True, nk=sweep sk=sweep
~~17: nk=64,64,64,64,64 sk=5,5,5,5,5 (done)
17. nk=64,64,64,64,64 sk=9,9,3,3,3
18. nk=64,64,64,64,64 sk=3,3,3,9,9
19: nk=8,16,32,64,128 sk=5,5,5,5,5
20. nk=8,16,32,64,128 sk=9,9,3,3,3
21. nk=8,16,32,64,128 sk=3,3,3,9,9
22: nk=128,64,32,16,8 sk=5,5,5,5,5
23. nk=128,64,32,16,8 sk=9,9,3,3,3
24. nk=128,64,32,16,8 sk=3,3,3,9,9

Choose best model from above sweeps and fine tune further: lr=1e-4, da=False, dr=0.3, act=?, bn=True, nk=? sk=?

sweeps 25-35 : epochs:15, lr=[lr_opt, lr_opt*10, lr_opt/10], batch_size: [32, 64], nfc: [1000, 2000]
~~25. lr: lr_opt, bs:64, nfc:1000 (done)
25. lr:lr_opt, bs:64, nfc:2000
26. lr:lr_opt, bs:32, nfc:1000
27. lr:lr_opt, bs:32, nfc:2000
28. lr:lr_opt*10, bs:64, nfc:1000
29. lr:lr_opt*10, bs:64, nfc:2000
30. lr:lr_opt*10, bs:32, nfc:1000
31. lr:lr_opt*10, bs:32, nfc:2000
32. lr:lr_opt/10, bs:64, nfc:1000
33. lr:lr_opt/10, bs:64, nfc:2000
34. lr:lr_opt/10, bs:32, nfc:1000
35. lr:lr_opt/10, bs:32, nfc:2000